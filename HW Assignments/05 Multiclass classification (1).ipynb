{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96f9137",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062aefb2",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "\n",
    "Additional note:\n",
    "\n",
    "* Please note that in this assignment, students are expected to work independently. As a result, no two solutions should look identical in terms of coding.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49457ef",
   "metadata": {},
   "source": [
    "``Objective``\n",
    "* Perform multiclass classification using logistic regression. <span style=\"color:chocolate\"> You will choose the outcome of interest. </span>\n",
    "\n",
    "``Motivation``\n",
    "* Chocolate is one of the most popular candies in the world. Each year, residents of the United States collectively eat more than 2.8 billions pounds (Source: Kaggle). However, not all chocolate bars are created equal! In this assignment, you will have the opportunity to delve into the world of chocolate by choosing your own machine learning task. \n",
    "\n",
    "\n",
    "``Data``\n",
    "\n",
    "* The [Chocolate Bar dataset](https://www.kaggle.com/datasets/rtatman/chocolate-bar-ratings) contains expert ratings of 1,795 individual chocolate bars, along with information on their regional origin, percentage of cocoa, the variety of chocolate bean used and where the beans were grown (Source: Kaggle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c135bf",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import pandas as pd\n",
    "import re\n",
    "import six\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9becda64",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd762410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    ''''''\n",
    "    # Read data\n",
    "    df = pd.read_csv(\n",
    "        \"https://download.mlcc.google.com/mledu-datasets/flavors_of_cacao.csv\",\n",
    "        sep=\",\",\n",
    "        encoding='latin-1'\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    ''''''\n",
    "    # Set the output display to have one digit for decimal places and limit it to\n",
    "    # printing 15 rows.\n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "    pd.options.display.max_rows = 15\n",
    "    \n",
    "    # Rename the columns.\n",
    "    df.columns = [\n",
    "        'maker', 'specific_origin', 'reference_number',\n",
    "        'review_date', 'cocoa_percent', 'maker_location',\n",
    "        'rating', 'bean_type', 'broad_origin'\n",
    "    ]\n",
    "\n",
    "    # df.dtypes\n",
    "\n",
    "    # Replace empty/null values with \"Blend\"\n",
    "    df['bean_type'] = df['bean_type'].fillna('Blend')\n",
    "\n",
    "    # Cast bean_type to string to remove leading 'u'\n",
    "    df['bean_type'] = df['bean_type'].astype(str)\n",
    "    df['cocoa_percent'] = df['cocoa_percent'].str.strip('%')\n",
    "    df['cocoa_percent'] = pd.to_numeric(df['cocoa_percent'])\n",
    "\n",
    "    # Correct spelling mistakes, and replace city with country name\n",
    "    df['maker_location'] = df['maker_location']\\\n",
    "    .str.replace('Amsterdam', 'Holland')\\\n",
    "    .str.replace('U.K.', 'England')\\\n",
    "    .str.replace('Niacragua', 'Nicaragua')\\\n",
    "    .str.replace('Domincan Republic', 'Dominican Republic')\n",
    "\n",
    "    # Adding this so that Holland and Netherlands map to the same country.\n",
    "    df['maker_location'] = df['maker_location']\\\n",
    "    .str.replace('Holland', 'Netherlands')\n",
    "\n",
    "    def cleanup_spelling_abbrev(text):\n",
    "        replacements = [\n",
    "            ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
    "            ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
    "            ['Mad,|Mad$', 'Madagascar, '],\n",
    "            ['PNG', 'Papua New Guinea, '],\n",
    "            ['Guat,|Guat$', 'Guatemala, '],\n",
    "            ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
    "            ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
    "            ['Nic,|Nic$', 'Nicaragua, '],\n",
    "            ['Cost Rica', 'Costa Rica'],\n",
    "            ['Mex,|Mex$', 'Mexico, '],\n",
    "            ['Jam,|Jam$', 'Jamaica, '],\n",
    "            ['Haw,|Haw$', 'Hawaii, '],\n",
    "            ['Gre,|Gre$', 'Grenada, '],\n",
    "            ['Tri,|Tri$', 'Trinidad, '],\n",
    "            ['C Am', 'Central America'],\n",
    "            ['S America', 'South America'],\n",
    "            [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
    "            [' Bali', ',Bali']\n",
    "        ]\n",
    "        for i, j in replacements:\n",
    "            text = re.sub(i, j, text)\n",
    "        return text\n",
    "\n",
    "    df['specific_origin'] = df['specific_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "    # Cast specific_origin to string\n",
    "    df['specific_origin'] = df['specific_origin'].astype(str)\n",
    "\n",
    "    # Replace null-valued fields with the same value as for specific_origin\n",
    "    df['broad_origin'] = df['broad_origin'].fillna(df['specific_origin'])\n",
    "\n",
    "    # Clean up spelling mistakes and deal with abbreviations\n",
    "    df['broad_origin'] = df['broad_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "    # Change 'Trinitario, Criollo' to \"Criollo, Trinitario\"\n",
    "    # Check with df['bean_type'].unique()\n",
    "    df.loc[df['bean_type'].isin(['Trinitario, Criollo']),'bean_type'] = \"Criollo, Trinitario\"\n",
    "    # Confirm with df[df['bean_type'].isin(['Trinitario, Criollo'])]\n",
    "\n",
    "    # Fix chocolate maker names\n",
    "    df.loc[df['maker']=='Shattel','maker'] = 'Shattell'\n",
    "    df['maker'] = df['maker'].str.replace(u'Na\\xef\\xbf\\xbdve','Naive')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c63c2e",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed182ba",
   "metadata": {},
   "source": [
    "First, we'll initiate the process of discovering the chocolate world by loading the data. Then, to assist with this assignment, we'll start by tidying up the data a little bit. This involves renaming columns and conducting some string preprocessing tasks, which will be handled by the <span style=\"color:chocolate\">clean_data()</span> function mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(read_data())\n",
    "print('Shape of data', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98257a7c",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 1:</span> Getting to know the data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f1439",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "    \n",
    "1. How many columns does the dataset contain?\n",
    "2. How many rows are there in the dataset?\n",
    "3. What are the column names?\n",
    "4. List the number of unique values for each column in the data;\n",
    "5. What do the reference and rating numbers represent? (Hint: read the dataset documentation and write down the interpretation for each number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf01d80",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 2:</span> Choosing the prediction task (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663edd18",
   "metadata": {},
   "source": [
    "Now that you've familiarized yourself with the data a little bit, select a multiclass outcome you're interested in predicting. Note: the outcome should have <span style=\"color:chocolate\">at least 3 classes</span>!\n",
    "\n",
    "Intuition: conducting a multi-class classification on this chocolate dataset can be incredibly valuable for several reasons: customer preferences and personalization, market analysis, R&D, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60c024",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a040c",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4d3d9",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 3:</span> Plots (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e58e51",
   "metadata": {},
   "source": [
    "In line with the structure of previous assignments, execute the following steps:\n",
    "\n",
    "1. Generate a minimum of 4 plots to investigate features within the dataset and the chosen outcome;\n",
    "2. Ensure that each plot includes clear axis labels and titles;\n",
    "3. Provide commentary on the insights learned from your visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09664286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283cad8f",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6ecb7",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 4:</span> Prepare data for modeling (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad52e5f",
   "metadata": {},
   "source": [
    "Following the format of previous assignments, adhere to the following steps as a minimum:\n",
    "\n",
    "1. Identify the features of interest;\n",
    "2. Perform necessary cleaning on the features;\n",
    "3. Reassess the outcome variable if desired (e.g., potentially reducing the number of classes, while ensuring a minimum of 3);\n",
    "4. Shuffle the dataset;\n",
    "5. Create training, validation, and test datasets using a 60/20/20 split;\n",
    "6. Standardize the data;\n",
    "7. Integrate any supplementary tasks deemed crucial for modeling, especially considering the chosen outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c295a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c017c",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Exploratory data analysis (EDA) - cont'd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdadb5",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 5:</span> More plots (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48673cf2",
   "metadata": {},
   "source": [
    "Conduct any further exploratory data analysis (EDA) you believe necessary to validate the successful preprocessing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e55a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3900b240",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1460403",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 6:</span> Baseline model (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f462623",
   "metadata": {},
   "source": [
    "When dealing with classification problems, a simple baseline is to select the *majority* class (the most common label in the training set) and use it as the prediction for all inputs.\n",
    "\n",
    "1. Implement this baseline and report the accuracy metric on the train data;\n",
    "\n",
    "2. Implement a function that computes the Log Loss (cross-entropy loss) metric and use it to evaluate this baseline on both the train and validation data. Note: reflect on what you know about the original distribution of classes in your training data (Hint: see Assignment 4 - Exercise 8 and ``Module Demos/05 Multiclass Logistic Regression.ipynb`` in bCourses for an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf889f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed92c3",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 7:</span> Improvement over baseline with Tensorflow (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31397655",
   "metadata": {},
   "source": [
    "Use TensorFlow (TF) to train a multiclass logistic regression model much like you did in Assignment 4. The goal here is to build a ML model to improve over the baseline classifier. You have the flexibility to choose which features to include.\n",
    "\n",
    "With this in mind, complete the following tasks:\n",
    "\n",
    "1. Build and compile a multiclass classification TF model (call it model_tf). Hint: the activation function, the loss, and the evaluation metric are different compared to the binary logistic regression (see ``Module Demos/05 Multiclass Logistic Regression.ipynb`` in bCourses for an example). Set learning_rate = 0.0001.\n",
    "2. Train model_tf using the training dataset and pass the validation data for validation. Set num_epochs = 10 and batch_size = 32.\n",
    "3. Generate a plot (for the training and validation data) with the loss values on the y-axis and the epoch number on the x-axis for visualization. Make sure to include axes name and title.\n",
    "\n",
    "If instructions for any other hyperparameters are not provided here, you are free to select your own or use the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1868df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a800d5",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6277d",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 8:</span> Choosing hyperparameters (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118fdcc",
   "metadata": {},
   "source": [
    "1. Fine-tune the hyperparameters of *model_tf* to determine the setup that yields the most optimal performance. Feel free to explore various values for the hyperparameters. Hint: ask your instructors and TAs for help if in doubt.\n",
    "\n",
    "After identifying your preferred model configuration, print the following information:\n",
    "\n",
    "2. The first five learned parameters of the model (this should include the bias term);\n",
    "3. The loss at the final epoch on both the training and validation datasets;\n",
    "4. The percentage difference between the losses observed on the training and validation datasets.\n",
    "5. Compare the training/validation loss of the TensorFlow model (model_tf) with the baseline model's loss. Does the TensorFlow model demonstrate an improvement over the baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd674a70",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Evaluation and generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6bc98",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 9:</span> Compute metrics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cb6cc",
   "metadata": {},
   "source": [
    "Now that you've determined the optimal set of hyperparameters, it's time to evaluate your optimized model on the test data to gauge its performance in real-world scenarios, commonly known as inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75cee6",
   "metadata": {},
   "source": [
    "1. Calculate aggregate accuracy on both train and test datasets. Note: you will need to convert the vector of predicted probabilities to a class label using the argmax operation. Hint: You can utilize the <span style=\"color:chocolate\">model.predict()</span> method provided by tf.keras. and the <span style=\"color:chocolate\">np.max()</span> method available in NumPy.\n",
    "\n",
    "2. Does the model demonstrate strong aggregate generalization capabilities? Provide an explanation based on your accuracy observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fcf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea764a",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 10:</span> Additional metrics (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a0a862",
   "metadata": {},
   "source": [
    "Using the test dataset:\n",
    "\n",
    "1. Plot the confusion matrix. Identify which class the model confuses the most.\n",
    "\n",
    "2. Determine which class has the lowest precision. What is the precision? Which class is the largest source of false positives?\n",
    "\n",
    "3. Determine which class has the lowest recall. What is the recall? Which class is the largest source of false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e9a5b",
   "metadata": {},
   "source": [
    "----\n",
    "### <span style=\"color:chocolate\">Bonus question</span> (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbae2a7",
   "metadata": {},
   "source": [
    "Following the approach in Assignment 4 - Exercise 12, evaluate whether your model shows any signs of unfairness. Explain your findings and propose suggestions for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
